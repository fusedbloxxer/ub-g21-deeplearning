{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import typing as t\n",
    "import numpy as np\n",
    "\n",
    "seed = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mLOCk6P-fldm"
   },
   "source": [
    "## Task I: Word-based CNN for Text Classification\n",
    "\n",
    "### 1. Data\n",
    "\n",
    "The dataset that we are going to use is the imdb dataset of movie reviews. These are labelled by sentiment (positive/negative). \n",
    "\n",
    "The reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). \n",
    "\n",
    "For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n",
    "\n",
    "More information regarding the dataset can be found in the official [documentation](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWg-G68bh2uI"
   },
   "source": [
    "### 2. Preprocess the text data \n",
    "\n",
    "In this particular case, where we are using the imdb dataset there is no need to do all the traditional preprocessings that we normally do when dealing with NLP problems. Part of them are already done at this point.\n",
    "\n",
    "  - Split the dataset in train and test (maybe also validation).\n",
    "  - Tokenize and transform to integer index. Here we would need to: \n",
    "    - instantitate a *Tokenizer()* object, \n",
    "    - fit that object on the text on which we are training the model (use the *fit_on_texts()* method)\n",
    "    - call *texts_to_sequences()* for both the training and the test text.\n",
    "\n",
    "  - **Add padding to ensure that all vectors have the same dimensionality.** Note that this is the only pre-processing that needs to be done in the case of the current imdb dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9a9ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBDataset(data.Dataset):\n",
    "    padding_idx: int = 10001\n",
    "\n",
    "    def __init__(self, length: int=1000, split: t.Literal['train', 'test']='train'):\n",
    "        super(IMDBDataset, self).__init__()\n",
    "\n",
    "        # Load the dataset\n",
    "        train_samples, train_labels, test_samples, test_labels = pickle.load(open('./imdb.pkl', 'rb'))\n",
    "\n",
    "        # Persist only the specific split\n",
    "        self.samples: t.List[t.List[int]] = train_samples if split == 'train' else test_samples\n",
    "        self.labels: t.List[int] = train_labels if split == 'train' else test_labels\n",
    "        self.length = length\n",
    "        self.padding_idx = IMDBDataset.padding_idx\n",
    "\n",
    "    def __getitem__(self, index) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        sample = self.samples[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        # Perform trimming\n",
    "        if len(sample) > self.length:\n",
    "            sample = sample[:self.length]\n",
    "\n",
    "        # Transform to tensor\n",
    "        sample = torch.tensor(sample)\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        # Perform padding\n",
    "        sample = torch.nn.functional.pad(sample, (0, self.length - len(sample)), value=self.padding_idx)\n",
    "        return sample, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "gen = torch.Generator(device='cpu').manual_seed(seed)\n",
    "train_data = IMDBDataset(split='train')\n",
    "test_data = IMDBDataset(split='test')\n",
    "train_data, valid_data = data.random_split(train_data, [0.8, 0.2], gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtIeukSXltKp"
   },
   "source": [
    "### 3.  Define the model de dataset and the training loop\n",
    "\n",
    "Similar to the privious lab while following the model architecture described in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvLayer(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_channels: int,\n",
    "                 output_channels: int,\n",
    "                 kernel_size: int,\n",
    "                 padding: int):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        # Create layers\n",
    "        self.conv = nn.Conv1d(in_channels=input_channels,\n",
    "                              out_channels=output_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding=padding)\n",
    "        self.bn = nn.BatchNorm1d(num_features=output_channels)\n",
    "        self.activ_fn = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        x: torch.Tensor = self.conv(input)\n",
    "        x = self.bn(x)\n",
    "        x = self.activ_fn(x)\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TextCNN(torch.nn.Module):\n",
    "    def __init__(self, padding_idx: int=IMDBDataset.padding_idx):\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        # Model Configuration\n",
    "        self.num_embeddings = 10002\n",
    "        self.embedding_dim = 100\n",
    "\n",
    "        # Define an embedding layer with a vocabulary size of 10002\n",
    "        # an output embedding size of 100\n",
    "        # and a padding_idx equal to the one used - 10001\n",
    "        self.embedding = nn.Embedding(num_embeddings=self.num_embeddings,\n",
    "                                      embedding_dim=self.embedding_dim,\n",
    "                                      padding_idx=padding_idx)\n",
    "\n",
    "        # Define the following sequence of layers\n",
    "        # A dropout layer with a probability of 0.4\n",
    "        self.drop1 = nn.Dropout(p=0.4)\n",
    "\n",
    "        # A 1D Convolutional layer with 100 input channels, 128 output channels, kernel size of 3 and a padding of 1\n",
    "        # A 1D Batch Normalization Layer for 128 features\n",
    "        # A ReLU activation\n",
    "        # A 1D Maxpooling layer with size 2\n",
    "        self.conv_layer1 = ConvLayer(100, 128, 3, 1)\n",
    "\n",
    "        # A 1D Convolutional layer with 128 input channels, 128 output channels, kernel size of 5 and a padding of 2\n",
    "        # A 1D Batch Normalization Layer for 128 features\n",
    "        # A ReLU activation\n",
    "        # A 1D Maxpooling layer with size 2\n",
    "        self.conv_layer2 = ConvLayer(128, 128, 5, 2)\n",
    "\n",
    "        # A 1D Convolutional layer with 128 input channels, 128 output channels, kernel size of 5 and a padding of 2\n",
    "        # A 1D Batch Normalization Layer for 128 features\n",
    "        # A ReLU activation\n",
    "        # A 1D Maxpooling layer with size 2\n",
    "        self.conv_layer3 = ConvLayer(128, 128, 5, 2)\n",
    "\n",
    "        # A global Average pooling layer, which in this scenario, will be an 1D Avgerage Pooling layer\n",
    "        # with size 125 and stride 125\n",
    "        self.pool = nn.AvgPool1d(125, 125)\n",
    "\n",
    "        # A Flattening layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # A Linear layer with 128 input features and 2 outputs and no activation function\n",
    "        self.dense = nn.Linear(in_features=128, out_features=2)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # forward the input through the embedding layer\n",
    "        x: torch.Tensor = self.embedding(input)\n",
    "\n",
    "        # permute the input such that it becomes channels first\n",
    "        x = x.permute((1, 0))\n",
    "\n",
    "        # forward the input through the rest of the sequence of layers\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.conv_layer3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = TextCNN()\n",
    "\n",
    "# instantiate the model\n",
    "# define an Adam optimizer for the model with a lr of 1e-3\n",
    "# define a Cross Entropy loss function\n",
    "\n",
    "# define the training dataset and dataloader and the test dataset and dataloader\n",
    "\n",
    "# write the training loop as defined in Lab 1 and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b973e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5a0f4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,  3797,    10,  ..., 10001, 10001, 10001])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([train_data[0][0], train_data[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7209d022",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 1000 elements not 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(sample)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 85\u001b[0m, in \u001b[0;36mTextCNN.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute((\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[1;32m     84\u001b[0m \u001b[39m# forward the input through the rest of the sequence of layers\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_layer1(x)\n\u001b[1;32m     86\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer2(x)\n\u001b[1;32m     87\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_layer3(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[64], line 23\u001b[0m, in \u001b[0;36mConvLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     22\u001b[0m     x: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv(\u001b[39minput\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn(x)\n\u001b[1;32m     24\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactiv_fn(x)\n\u001b[1;32m     25\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(x)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/lab2-CPSerQ_o-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2479\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2480\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 1000 elements not 128"
     ]
    }
   ],
   "source": [
    "model(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
