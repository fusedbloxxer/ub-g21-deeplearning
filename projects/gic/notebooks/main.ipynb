{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External libraries\n",
    "import os as so\n",
    "import sys as s\n",
    "import pathlib as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torcheval\n",
    "from torcheval.metrics import MulticlassF1Score, Mean\n",
    "import optuna as opt\n",
    "import torchvision as tn\n",
    "import sklearn as sn\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as ps\n",
    "import numpy as ny\n",
    "import typing as t\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as pt\n",
    "import random as rng\n",
    "from tqdm import tqdm\n",
    "import tqdm as tm\n",
    "from pprint import pprint\n",
    "from git import Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33minvokariman\u001b[0m (\u001b[33mcastelvaar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/__init__.py:58: ExperimentalWarning: WeightsAndBiasesCallback is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  wn_callback = WeightsAndBiasesCallback(\n",
      "/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/tune.py:98: ExperimentalWarning: track_in_wandb is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  @forward_self(wn_callback.track_in_wandb())\n"
     ]
    }
   ],
   "source": [
    "# Add local package to path\n",
    "if (p := pl.Path(so.getcwd(), '..').absolute().as_posix()) not in s.path:\n",
    "    s.path.append(p)\n",
    "\n",
    "# Local imports\n",
    "from gic import *\n",
    "from gic.tune import HyperParameterSampler, ClassificationTrainer\n",
    "from gic.data import load_data, GenImageDataset\n",
    "from gic.model import ResCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search hyperparameters in a subspace\n",
    "sampler = HyperParameterSampler(lambda trial: {\n",
    "    'batch_size': trial.suggest_int('batch_size', 8, 32, step=16),\n",
    "    'optimizer': trial.suggest_categorical('optimizer', ['Adam', 'AdamW']),\n",
    "    'lr': trial.suggest_float('lr', 1e-4, 4e-3),\n",
    "    'epochs': trial.suggest_int('epochs', 40, 60),\n",
    "    'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3),\n",
    "    'pool': trial.suggest_categorical('pool', ['max', 'avg']),\n",
    "    'dropout1d': trial.suggest_float('dense_dropout', 0.2, 0.6),\n",
    "    'dropout2d': trial.suggest_float('conv_dropout', 0.3, 0.6),\n",
    "    'conv_chan': trial.suggest_int('conv_chan', 16, 32, step=8),\n",
    "    'dens_chan': trial.suggest_int('dens_chan', 128, 1024, 512),\n",
    "    'activ_fn': trial.suggest_categorical('activ', ['ReLU', 'SiLU', 'GELU'])\n",
    "})\n",
    "\n",
    "# Find the best model using a trainer\n",
    "trainer = ClassificationTrainer(\n",
    "    model=ResCNN,\n",
    "    seed=SEED,\n",
    "    hps=sampler,\n",
    "    device=DEVICE,\n",
    "    dataset_path=DATA_PATH,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=prefetch_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-01 01:44:12,753] A new study created in RDB with name: no-name-cbeda2d6-774a-4624-8fe2-bcecb1c00c87\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path ../tracking/wandb/ wasn't writable, using system temp directory.\n",
      "wandb: WARNING Path ../tracking/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20231201_014412-7amaionu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/castelvaar/Generated%20Image%20Classification/runs/7amaionu' target=\"_blank\">resilient-darkness-89</a></strong> to <a href='https://wandb.ai/castelvaar/Generated%20Image%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/castelvaar/Generated%20Image%20Classification' target=\"_blank\">https://wandb.ai/castelvaar/Generated%20Image%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/castelvaar/Generated%20Image%20Classification/runs/7amaionu' target=\"_blank\">https://wandb.ai/castelvaar/Generated%20Image%20Classification/runs/7amaionu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [8, 32] and step=16, but the range is not divisible by `step`. It will be replaced by [8, 24].\n",
      "  warnings.warn(\n",
      "/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/distributions.py:700: UserWarning: The distribution is specified by [128, 1024] and step=512, but the range is not divisible by `step`. It will be replaced by [128, 640].\n",
      "  warnings.warn(\n",
      "train_batch: 100%|██████████| 1500/1500 [00:07<00:00, 211.32it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 349.38it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.04it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 351.30it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.32it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 346.67it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 221.16it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 347.53it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.10it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 349.85it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 220.67it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 343.33it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 225.17it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 346.51it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.66it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 348.56it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.25it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 344.56it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.27it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 348.04it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.91it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 345.59it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 219.70it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 345.98it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 219.87it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 347.57it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 218.86it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 354.43it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 220.28it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 346.03it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 215.20it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 347.92it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 215.33it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 349.06it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 216.47it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 347.75it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 215.23it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 345.47it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 214.98it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 344.42it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.76it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 344.98it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.09it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 342.71it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.28it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 344.08it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.20it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 344.93it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.65it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 353.08it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 220.87it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 349.45it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.33it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 343.35it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 219.90it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 350.36it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 217.12it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 343.82it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 228.53it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 347.11it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 218.99it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 348.42it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.79it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 345.73it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.27it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 346.96it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.66it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 350.19it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.51it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 350.78it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 219.99it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 349.19it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.21it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 349.62it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 223.44it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 351.17it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.12it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 350.31it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.46it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 354.87it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 222.23it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 346.71it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.39it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 353.93it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 220.86it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 347.42it/s]\n",
      "train_batch: 100%|██████████| 1500/1500 [00:06<00:00, 224.32it/s]\n",
      "valid_batch: 100%|██████████| 375/375 [00:01<00:00, 346.82it/s]\n",
      "train_batch:  42%|████▏     | 624/1500 [00:02<00:03, 222.62it/s]\n",
      "epoch:  98%|█████████▊| 44/45 [05:49<00:07,  7.95s/it]\n",
      "[W 2023-12-01 01:50:03,357] Trial 0 failed with parameters: {'batch_size': 8, 'optimizer': 'AdamW', 'lr': 0.00013042084716234596, 'epochs': 45, 'weight_decay': 0.00063217499863753, 'pool': 'avg', 'dense_dropout': 0.5908077569215953, 'conv_dropout': 0.43606675395538697, 'conv_chan': 32, 'dens_chan': 128, 'activ': 'SiLU'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/utils.py\", line 26, in hidden\n",
      "    return hide_self(callback(show_self(procedure)))(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/utils.py\", line 9, in hidden\n",
      "    return procedure(trial)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/integration/wandb.py\", line 225, in wrapper\n",
      "    return func(trial)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/utils.py\", line 17, in hidden\n",
      "    return procedure(trial.inner, trial)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/tune.py\", line 120, in __call__\n",
      "    train_f1_score = self.train_step(epoch)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/tune.py\", line 179, in train_step\n",
      "    for X, y in self.train_lr_:\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 302, in __getitem__\n",
      "    return self.datasets[dataset_idx][sample_idx]\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/data.py\", line 38, in __getitem__\n",
      "    image: Tensor = tn.io.read_image(image_path, tn.io.ImageReadMode.RGB)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torchvision/io/image.py\", line 259, in read_image\n",
      "    return decode_image(data, mode)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torchvision/io/image.py\", line 236, in decode_image\n",
      "    output = torch.ops.image.decode_image(input, mode.value)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/invokariman/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/_ops.py\", line 692, in __call__\n",
      "    return self._op(*args, **kwargs or {})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2023-12-01 01:50:03,358] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/main.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/main.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m searcher \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mTPESampler(n_startup_trials\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/main.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m search \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, storage\u001b[39m=\u001b[39mdb_uri, sampler\u001b[39m=\u001b[39msearcher, pruner\u001b[39m=\u001b[39mcutoff)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/main.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m search\u001b[39m.\u001b[39;49moptimize(trainer, n_trials\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[wn_callback])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/invokariman/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/main.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m wn\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/utils.py:26\u001b[0m, in \u001b[0;36mforward_self.<locals>.forward_inner.<locals>.hidden\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@wraps\u001b[39m(procedure)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhidden\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m hide_self(callback(show_self(procedure)))(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/utils.py:9\u001b[0m, in \u001b[0;36mhide_self.<locals>.hidden\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m@wraps\u001b[39m(procedure)\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhidden\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[1;32m      8\u001b[0m     trial\u001b[39m.\u001b[39minner \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m procedure(trial)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/optuna/integration/wandb.py:225\u001b[0m, in \u001b[0;36mWeightsAndBiasesCallback.track_in_wandb.<locals>.decorator.<locals>.wrapper\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    222\u001b[0m     run \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_run()\n\u001b[1;32m    223\u001b[0m     run\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrial/\u001b[39m\u001b[39m{\u001b[39;00mtrial\u001b[39m.\u001b[39mnumber\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 225\u001b[0m \u001b[39mreturn\u001b[39;00m func(trial)\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/utils.py:17\u001b[0m, in \u001b[0;36mshow_self.<locals>.hidden\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m@wraps\u001b[39m(procedure)\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhidden\u001b[39m(trial):\n\u001b[0;32m---> 17\u001b[0m     \u001b[39mreturn\u001b[39;00m procedure(trial\u001b[39m.\u001b[39;49minner, trial)\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/tune.py:120\u001b[0m, in \u001b[0;36mClassificationTrainer.__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    118\u001b[0m valid_f1_score: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tm\u001b[39m.\u001b[39mtrange(hparams[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m], desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m--> 120\u001b[0m     train_f1_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(epoch)\n\u001b[1;32m    121\u001b[0m     valid_f1_score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_step(epoch, trial)\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m valid_f1_score\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/tune.py:179\u001b[0m, in \u001b[0;36mClassificationTrainer.train_step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39m# Perform a training iteration across the entire dataset\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mwith\u001b[39;00m tm\u001b[39m.\u001b[39mtqdm(desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain_batch\u001b[39m\u001b[39m'\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_lr_), position\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mas\u001b[39;00m batch:\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mfor\u001b[39;49;00m X, y \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_lr_:\n\u001b[1;32m    180\u001b[0m         \u001b[39m# Send data to GPU\u001b[39;49;00m\n\u001b[1;32m    181\u001b[0m         X: Tensor \u001b[39m=\u001b[39;49m X\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_)\n\u001b[1;32m    182\u001b[0m         y_true: Tensor \u001b[39m=\u001b[39;49m y\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m indices]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/utils/data/dataset.py:302\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m--> 302\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[0;32m~/Projects/git/ub-g21-deeplearning/projects/gic/notebooks/../gic/data.py:38\u001b[0m, in \u001b[0;36mGenImageDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     36\u001b[0m image_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__data\u001b[39m.\u001b[39miloc[index]\u001b[39m.\u001b[39mloc[\u001b[39m'\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     37\u001b[0m image_path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__imag \u001b[39m/\u001b[39m image_name)\n\u001b[0;32m---> 38\u001b[0m image: Tensor \u001b[39m=\u001b[39m tn\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_image(image_path, tn\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mImageReadMode\u001b[39m.\u001b[39;49mRGB)\n\u001b[1;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__preprocess:\n\u001b[1;32m     41\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__transform(image)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torchvision/io/image.py:259\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    257\u001b[0m     _log_api_usage_once(read_image)\n\u001b[1;32m    258\u001b[0m data \u001b[39m=\u001b[39m read_file(path)\n\u001b[0;32m--> 259\u001b[0m \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torchvision/io/image.py:236\u001b[0m, in \u001b[0;36mdecode_image\u001b[0;34m(input, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_scripting() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mis_tracing():\n\u001b[1;32m    235\u001b[0m     _log_api_usage_once(decode_image)\n\u001b[0;32m--> 236\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mdecode_image(\u001b[39minput\u001b[39;49m, mode\u001b[39m.\u001b[39;49mvalue)\n\u001b[1;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gic-BfYgXNhZ-py3.11/lib/python3.11/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search hyperparams\n",
    "cutoff = opt.pruners.HyperbandPruner()\n",
    "searcher = opt.samplers.TPESampler(n_startup_trials=10)\n",
    "search = opt.create_study(direction='maximize', storage=db_uri, sampler=searcher, pruner=cutoff)\n",
    "search.optimize(trainer, n_trials=30, callbacks=[wn_callback])\n",
    "wn.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'optimizer': 'Adam',\n",
       " 'lr': 0.00042881479787811055,\n",
       " 'epochs': 27,\n",
       " 'weight_decay': 0.0004010257351593616,\n",
       " 'poo': 'avg',\n",
       " 'dense_dropout': 0.0736934008960651,\n",
       " 'conv_dropout': 0.29165493134158693,\n",
       " 'conv_chan': 24,\n",
       " 'dens_chan': 512,\n",
       " 'activ': 'LeakyReLU'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best model parameters\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr': 3e-4,\n",
    "    'epochs': 50,\n",
    "    'weight_decay': 5e-5,\n",
    "    'pool': 'avg',\n",
    "    'dense_dropout': 0.3,\n",
    "    'conv_dropout': 0.4,\n",
    "    'conv_chan': 32,\n",
    "    'dens_chan': 512,\n",
    "    'activ': 'SiLU'\n",
    "}\n",
    "\n",
    "# Train on `almost` the whole labeled dataset\n",
    "# trainer.train(params)\n",
    "# wn.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_batch:   0%|          | 0/313 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[67, 42, 40, 13, 69, 45, 24, 54, 26, 98]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds: t.List[int] = trainer.eval(params).tolist()\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = GenImageDataset(DATA_PATH, 'test', True)\n",
    "dataf = {'Image': [], 'Class': []}\n",
    "dataf['Class'] = preds\n",
    "test_data._GenImageDataset__data['Class'] = preds\n",
    "test_data._GenImageDataset__data.to_csv(SUBMISSION_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gic-BfYgXNhZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
